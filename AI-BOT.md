# Задача: Реализация AI (LLM) ответов в чате (Пункт 1.1)

## Описание
На текущий момент чат-бот работает в режиме "калькулятора" — он следует жестко прописанной воронке, но при переходе в режим свободного общения (`FREE_CHAT`) выдаёт заглушку. Бэкенд сохраняет сообщения пользователя, но не вызывает сервис ИИ для генерации ответа.

## Цель
1.  Обеспечить вызов LLM (через RouterAI и Qdrant) при получении сообщений от пользователя в режиме свободного общения.
2.  Убрать фронтенд-заглушки и наладить передачу сообщений на бэкенд через WebSocket.

## Технический контекст

### Бэкенд
- **Файл**: `backend/src/routes/ws.ts`
- **Проблема**: В обработчике `socket.on('message', ...)` для клиентов (строки 160-179) сообщения пользователя (`role === 'user'`) только сохраняются в БД и рассылаются админам.
- **Решение**: Если сессия находится в состоянии отличным от воронки (или просто всегда для `role === 'user'`, если это уместно по логике), нужно вызвать `handleFreeChat` из `backend/src/services/chatService.ts`.
- **Сервис**: `backend/src/services/chatService.ts` уже содержит функцию `handleFreeChat`, которая работает с RouterAI и RAG (через `ragService.ts`). Её нужно просто подключить к WebSocket.

### Фронтенд
- **Файл**: `frontend/src/store/chatStore.ts`
- **Проблема**: 
    1.  В методе `sendUserMessage` (строки 219-407) для состояния `FREE_CHAT` (строки 401-407) стоит `setTimeout` с хардкод-ответом: *"Пока я работаю в демо-режиме..."*.
    2.  Метод должен дождаться ответа от бэкенда по WebSocket (событие с типом `message` и `role === 'bot'`).
- **Решение**: Удалить хардкод-заглушку. Убедиться, что при отправке сообщения в `FREE_CHAT` оно уходит в сокет (это уже должно работать, так как `socket.send` вызывается в начале метода).

### Настройки моделей (RouterAI)
В настройках тенанта (Integration settings) должны поддерживаться и корректно передаваться в `handleFreeChat` следующие модели:
- `anthropic/claude-sonnet-4.6`
- `openai/gpt-5.2`
- `deepseek/deepseek-v3.2`

> [!IMPORTANT]
> При реализации учитывай правила из `GEMINI.md` и `AGENTS.md`. Бэкенд на JS (хотя файлы сейчас `.ts`, придерживайся текущего стиля).

## План выполнения (для тебя)
1.  **Backend**: В `ws.ts` добавь вызов `handleFreeChat` после сохранения сообщения пользователя.
2.  **Backend**: Полученный ответ от `handleFreeChat` (если он не null) отправь обратно пользователю через `socket.send` и сохрани в БД через `saveMessage`.
3.  **Frontend**: В `chatStore.ts` удали блок кода с заглушкой в `chatState === 'FREE_CHAT'`.
4.  **Verification**: Проверь, что в чате после завершения воронки (в состоянии `FREE_CHAT`) Макс отвечает на произвольные вопросы, используя базу знаний тенанта.

## Ссылки на документацию
- [GEMINI.md](file:///c:/dev/ai-chat-lend/GEMINI.md) — общие правила.
- [ADMINPANEL.md](file:///c:/dev/ai-chat-lend/ADMINPANEL.md) — спецификация интеграций.
- [REPORT-FINAL.md](file:///c:/dev/ai-chat-lend/REPORT-FINAL.md) — исходный отчет об ошибке (пункт 1.1).
