# Фаза 8: Реализация RAG (База знаний и свободные вопросы) (v1.2)

## Контекст

Фаза 7 (Генерация PDF-смет) успешно завершена. Бот способен проводить пользователя по воронке, рассчитывать стоимость ремонта на основе матриц цен тенанта, генерировать PDF и отправлять их в Telegram.

Следующий крупный шаг в развитии платформы — **реализация RAG (Retrieval-Augmented Generation)**. В данный момент бот работает строго по скрипту воронки. Необходимо дать пользователям возможность задавать "свободные вопросы" (о компании, гарантиях, сроках, технологиях ремонта) и получать ответы, опирающиеся на загруженную базу знаний (документы тенанта), а не на галлюцинации LLM.

## Архитектура RAG

- **Векторная БД**: Qdrant (self-hosted в Docker, уже запущен на порту 6333, `http://qdrant:6333`).
- **Смыслобуфер (Embeddings)**: Использование LLM-шлюза RouterAI (или OpenAI API) для получения эмбеддингов текста (`text-embedding-3-small` или аналог).
- **Коллекции в Qdrant**: На каждую компанию (тенанта) должна быть либо отдельная коллекция `tenant_{id}`, либо общая коллекция `knowledge_base` с обязательной фильтрацией по `tenant_id` в payload каждого вектора (предпочтительнее второй вариант для масштабируемости).

## Цели Фазы 8

1. **Сервис Базиса знаний (Knowledge Service)**: Написать логику чанкинга текстовых документов, получения их векторного представления (эмбеддингов) и сохранения в Qdrant.
2. **Админка (Backend + Frontend)**: Позволить владельцу тенанта загружать `.txt`, `.md` или текстовые данные в свою базу знаний через интерфейс админки.
3. **Модификация ChatBot Service**: Интегрировать RAG в процесс обработки сообщений вне воронки (в состоянии `FREE_CHAT` или при прерывании воронки).
4. **Улучшение промптов**: Настроить системный промпт LLM так, чтобы она использовала предоставленный контекст базы знаний для ответов на вопросы пользователя.

## Структура задач

### 1. Подготовка инфраструктуры Qdrant
- [ ] Описать интерфейс работы с Qdrant (через HTTP API или официальный SDK `@qdrant/js-client-rest`).
- [ ] Написать скрипт/функцию `initQdrant.ts` для создания коллекции `knowledge_base` с нужной размерностью векторов (совпадающей с моделью эмбеддингов) при старте бэкенда.

### 2. Backend: Сервис управления знаниями
- [ ] Создать `backend/src/services/ragService.ts`. Реализовать методы:
  - `addDocument(tenantId, text, sourceName)`: Чанкинг текста -> запрос эмбеддингов -> сохранение в Qdrant с `payload: { tenantId, sourceName }`.
  - `searchKnowledge(tenantId, query, topK = 3)`: Получение эмбеддинга запроса -> поиск ближайших векторов в Qdrant с фильтрацией по `tenant_id` -> возврат объединеного текста.
  - `deleteDocument(tenantId, docId)`: Удаление векторов конкретного документа.

### 3. Backend: Интеграция RAG в чат
- [ ] В `chatHandler.ts` / сервисе LLM обновить логику свободного общения: 
  - Когда пользователь задает вопрос вне контекста воронки, вызвать `ragService.searchKnowledge()`.
  - Сформировать RAG-промпт: "Используй следующую информацию для ответа на вопрос пользователя: {context}. Отвечай кратко, от лица эксперта Макса...".
  - Отправить запрос к RouterAI / LLM с новым промптом.
- [ ] Настроить логику **Escalation / Human Takeover**: Если Qdrant не нашел ответа / контекста, бот должен вежливо ответить, что не знает точного ответа, и предложить перевести диалог на менеджера.

### 4. Admin API (Управление RAG)
- [ ] Реализовать endpoints в `tenantAdminRoutes`:
  - `GET /api/t/:slug/admin/bot/knowledge` - список загруженных документов.
  - `POST /api/t/:slug/admin/bot/knowledge/upload` - загрузка нового текста/настроек.
  - `DELETE /api/t/:slug/admin/bot/knowledge/:docId` - удаление текста.

### 5. Frontend UI для базы знаний
- [ ] Создать компонент \`TenantKnowledgeBase.tsx\` в админке `frontend/src/pages/tenant/tabs/`.
- [ ] Добавить форму загрузки текста (TextArea) или файлов.
- [ ] Добавить отображение списка текущих знаний с кнопкой удаления.

## Технические нюансы
- Ограничение размера чанков (например, по 500-1000 токенов/символов) с небольшим перекрытием (overlap = 100 символов) для лучшего семантического поиска.
- Для получения эмбеддингов использовать доступный API (например, OpenAI API или модель, поддерживаемую RouterAI, которая возвращает вектора). 
- Обработка ошибок Qdrant (если сервис недоступен, бот должен всё равно уметь общаться `FREE_CHAT` без базы знаний, переходя в режим заглушки).

---
*Сохраните данный файл как контекст для следующей сессии с AI Агентом.*
